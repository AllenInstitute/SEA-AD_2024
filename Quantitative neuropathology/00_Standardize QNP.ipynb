{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb2aad0-38fa-45ce-b7ae-c7ff4cf2c4ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17b3b0-f02e-41b4-a60a-d1b83b9c7713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import anndata\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "import copy\n",
    "import glob\n",
    "import pyreadstat\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from igraph import *\n",
    "import warnings\n",
    "\n",
    "sc.settings.n_jobs = 32\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9eb2c-06b0-4d05-8a99-b12ac23bae61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_quant_neuropath(region, pivot=True):\n",
    "    quant_csvs = glob.glob(os.path.join(pwd, \"input\", \"quant_neuropath\", region, \"raw\", \"*.csv\"))\n",
    "    original_names = []\n",
    "    updated_names = []\n",
    "    for i in quant_csvs:\n",
    "        print(\"Processing \" + os.path.basename(i))\n",
    "        tmp = pd.read_csv(i)\n",
    "        final_grey_matter = None\n",
    "        if \"Image Tag\" in tmp.columns:\n",
    "            tmp.drop([\"Image Tag\"], axis=1, inplace=True)\n",
    "        replace_dict = {\n",
    "            \"(μm²)\": \"\",\n",
    "            \"(μm)\": \"\",\n",
    "            \"per μm²\": \"per area\",\n",
    "            \"pg/ug\": \"\",\n",
    "            \"tissue area\": \"area\",\n",
    "            \"tissue\\n\": \"area\",\n",
    "            \"avg\": \"average\",\n",
    "            \"  \": \" \",\n",
    "            \"total of\": \"total\",\n",
    "            \"positive bearing\": \"positive\",\n",
    "            \"positive inclusion bearing\": \"positive\",\n",
    "            \"total hematoxylin nuclei\": \"number of Hematoxylin positive nuclei\",\n",
    "            \"hematoxylin stained\": \"Hematoxylin positive\",\n",
    "            \"Hematoxylin positive average\": \"average Hematoxylin positive\",\n",
    "            \"hematoxylin average nucleus roundness\": \"average hematoxylin positive nucleus roundness\",\n",
    "            \"number 6e10 positive objects\": \"number of 6e10 positive objects\",\n",
    "            \"average 6e10 positive objects area\": \"average 6e10 positive object area\",\n",
    "            \"average 6e10 positive objects median diameter\": \"average 6e10 positive object median diameter\",\n",
    "            \"iba1 positive and 6e10 positive\": \"Iba1 and 6e10 positive\",\n",
    "            \"objects colocalized\": \"co-localized objects\",\n",
    "            \"total iba1 positive cells\": \"number of Iba1 positive cells\",\n",
    "            \"total activated iba1 positive cells\": \"number of activated Iba1 positive cells\",\n",
    "            \"total inactivated iba1 positive cells\": \"number of inactivated Iba1 positive cells\",\n",
    "            \"average gfap positive length\": \"average GFAP positive branch length\",\n",
    "            \"at8\": \"AT8\",\n",
    "            \"ptdp43\": \"pTDP43\",\n",
    "            \"a-syn\": \"aSyn\",\n",
    "            \"iba1\": \"Iba1\",\n",
    "            \"gfap\": \"GFAP\",\n",
    "            \"neun\": \"NeuN\",\n",
    "            \"ttau\": \"tTau\",\n",
    "            \"ptau\": \"pTau\",\n",
    "        }\n",
    "        regex_dict = {\n",
    "            \"^(.*) tissue$\": \"\\\\1 area\",\n",
    "            \"^(.*) $\": \"\\\\1\"\n",
    "        }\n",
    "\n",
    "        original_names.extend(tmp.columns.to_list())\n",
    "        tmp.columns = [str.lower(j) for j in tmp.columns]\n",
    "        fixed_names = tmp.columns.to_list()\n",
    "        for j,k in enumerate(tmp.columns):\n",
    "            for l,m in replace_dict.items():\n",
    "                fixed_names[j] = fixed_names[j].replace(l, m)\n",
    "            for l,m in regex_dict.items():\n",
    "                fixed_names[j] = re.sub(l, m, fixed_names[j])\n",
    "        tmp.columns = fixed_names\n",
    "\n",
    "        updated_names.extend(tmp.columns.to_list())\n",
    "\n",
    "        \n",
    "        for j in tmp.columns[tmp.columns.str.startswith(\"number of\")]:\n",
    "            if j.endswith(\"per area\") == False:\n",
    "                tmp[j + \" per area\"] = tmp[j] / tmp[\"area analyzed\"]\n",
    "        \n",
    "        stain_name = {\n",
    "            \"AT-MTG-Summary Data-01-31-22.csv\": \"AT8 and pTDP43\",\n",
    "            \"Hematoxylin-MTG-Summary data-01-29-22.csv\": \"Hematoxylin\",\n",
    "            \"a-Syn-MTG-Summary data-01-29-22.csv\": \"aSyn\",\n",
    "            \"I6-MTG-Summary data-08-10-22.csv\": \"Iba1 and 6e10\",\n",
    "            \"NeuN-MTG-Summary data-01-26-22.csv\": \"NeuN\",\n",
    "            \"GFAP-MTG-Summary Data-01-29-22.csv\": \"GFAP\",\n",
    "        }\n",
    "\n",
    "        if \"analysis region\" in tmp.columns:\n",
    "            tmp.loc[: \"analysis region\"] = tmp.loc[: \"analysis region\"].replace(\"Layer I\", \"Layer1\")\n",
    "            for j in tmp.columns:\n",
    "                if j.startswith(\"number of\") is True and j.endswith(\"per area\") is False:\n",
    "                    grey_matter = tmp.loc[:, [j, \"case number\"]].groupby(\"case number\").sum()\n",
    "                    grey_matter[\"analysis region\"] = \"Grey matter\"\n",
    "                    try:\n",
    "                        final_grey_matter = pd.concat([final_grey_matter, grey_matter], axis=1)\n",
    "                        final_grey_matter = final_grey_matter.loc[:, ~(final_grey_matter.columns.duplicated())]\n",
    "\n",
    "                    except:\n",
    "                        final_grey_matter = grey_matter.copy()\n",
    "                elif j.startswith(\"total\") is True:\n",
    "                    grey_matter = tmp.loc[:, [j, \"case number\"]].groupby(\"case number\").sum()\n",
    "                    grey_matter[\"analysis region\"] = \"Grey matter\"\n",
    "                    try:\n",
    "                        final_grey_matter = pd.concat([final_grey_matter, grey_matter], axis=1)\n",
    "                        final_grey_matter = final_grey_matter.loc[:, ~(final_grey_matter.columns.duplicated())]\n",
    "                    except:\n",
    "                        final_grey_matter = grey_matter.copy()\n",
    "                elif j == \"area analyzed\":\n",
    "                    grey_matter = tmp.loc[:, [j, \"case number\"]].groupby(\"case number\").sum()\n",
    "                    grey_matter[\"analysis region\"] = \"Grey matter\"\n",
    "                    try:\n",
    "                        final_grey_matter = pd.concat([final_grey_matter, grey_matter], axis=1)\n",
    "                        final_grey_matter = final_grey_matter.loc[:, ~(final_grey_matter.columns.duplicated())]\n",
    "                    except:\n",
    "                        final_grey_matter = grey_matter.copy()\n",
    "                elif j.startswith(\"percent\") is True or j.startswith(\"average\") is True:\n",
    "                    grey_matter = tmp.loc[:, [j, \"case number\", \"area analyzed\"]]\n",
    "                    grey_matter[j + \"_weighted\"] = grey_matter[j] * grey_matter[\"area analyzed\"]\n",
    "                    grey_matter = grey_matter.loc[:, [j + \"_weighted\", \"area analyzed\", \"case number\"]].groupby(\"case number\").sum()\n",
    "                    grey_matter[j] = grey_matter[j + \"_weighted\"] / grey_matter[\"area analyzed\"]\n",
    "                    grey_matter.drop([j + \"_weighted\", \"area analyzed\"], axis=1, inplace=True)\n",
    "                    grey_matter[\"analysis region\"] = \"Grey matter\"\n",
    "                    try:\n",
    "                        final_grey_matter = pd.concat([final_grey_matter, grey_matter], axis=1)\n",
    "                        final_grey_matter = final_grey_matter.loc[:, ~(final_grey_matter.columns.duplicated())]\n",
    "                    except:\n",
    "                        final_grey_matter = grey_matter.copy()\n",
    "                        \n",
    "                elif j.startswith(\"number of\") is True and j.endswith(\"per area\") is True:\n",
    "                    grey_matter = tmp.loc[:, [j, \"case number\", \"area analyzed\"]]\n",
    "                    grey_matter[j + \"_weighted\"] = grey_matter[j] * grey_matter[\"area analyzed\"]\n",
    "                    grey_matter = grey_matter.loc[:, [j + \"_weighted\", \"area analyzed\", \"case number\"]].groupby(\"case number\").sum()\n",
    "                    grey_matter[j] = grey_matter[j + \"_weighted\"] / grey_matter[\"area analyzed\"]\n",
    "                    grey_matter.drop([j + \"_weighted\", \"area analyzed\"], axis=1, inplace=True)\n",
    "                    grey_matter[\"analysis region\"] = \"Grey matter\"\n",
    "                    try:\n",
    "                        final_grey_matter = pd.concat([final_grey_matter, grey_matter], axis=1)\n",
    "                        final_grey_matter = final_grey_matter.loc[:, ~(final_grey_matter.columns.duplicated())]\n",
    "                    except:\n",
    "                        final_grey_matter = grey_matter.copy()\n",
    "            \n",
    "            final_grey_matter.reset_index(inplace=True)     \n",
    "            tmp = pd.concat([tmp, final_grey_matter], axis=0)\n",
    "            \n",
    "        else:\n",
    "            tmp[\"analysis region\"] = \"Grey matter\"\n",
    "            \n",
    "        if \"area analyzed\" in tmp.columns:\n",
    "            tmp[stain_name[os.path.basename(i)] + \" area analyzed\"] = tmp[\"area analyzed\"].copy()\n",
    "            tmp.drop([\"area analyzed\"], axis=1, inplace=True)\n",
    "                    \n",
    "        if pivot == True:\n",
    "            tmp = tmp.pivot(index=\"case number\", columns=[\"analysis region\"])\n",
    "            tmp.columns = ['_'.join(j) for j in tmp.columns.values]\n",
    "            if tmp.index.name != \"case number\":\n",
    "                tmp.index = tmp[\"case number\"].copy()\n",
    "                tmp.drop(\"case number\", axis=1, inplace=True)\n",
    "                    \n",
    "            tmp = tmp.sort_index()\n",
    "\n",
    "        else:\n",
    "            tmp.index = pd.Index(tmp.loc[:, [\"case number\", \"analysis region\"]])\n",
    "            tmp.index = pd.MultiIndex.from_tuples(tmp.index, names=[\"case number\", \"analysis region\"])\n",
    "            tmp.drop([\"case number\", \"analysis region\"], axis=1, inplace=True)\n",
    "            tmp = tmp.sort_index()\n",
    "     \n",
    "        try:\n",
    "            final_table = final_table.merge(tmp, left_index=True, right_index=True, how=\"left\")\n",
    "        \n",
    "        except UnboundLocalError:\n",
    "            final_table = tmp.copy()\n",
    "\n",
    "    final_table.reset_index(inplace=True)\n",
    "    if pivot == True: \n",
    "        savefile = os.path.join(pwd, \"input\", \"quant_neuropath\", region, \"processed\", \"all_quant_neuropath_by_donor_pivoted.\" + str(datetime.date(datetime.now())) + \".csv\")\n",
    "    \n",
    "    else:\n",
    "        savefile = os.path.join(pwd, \"input\", \"quant_neuropath\", region, \"processed\", \"all_quant_neuropath_by_donor.\" + str(datetime.date(datetime.now())) + \".csv\")\n",
    "    pd.DataFrame([original_names, updated_names]).T.to_csv(\"original_to_new.csv\")\n",
    "    final_table.to_csv(savefile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b42945-df90-4169-a6e1-f359006b8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_quant_neuropath(\"MTG\", pivot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394cf794-acc0-49c4-a11b-e0f5843fac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_quant_neuropath(\"MTG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
