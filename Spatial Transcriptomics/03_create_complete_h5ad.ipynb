{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad274f1-e3b6-41fc-b5ed-75b19c544026",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from pathlib import Path\n",
    "from scanpy import read_h5ad\n",
    "from umap import UMAP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata\n",
    "\n",
    "#load filepaths\n",
    "root_folder = '/allen/programs/celltypes/workgroups/hct/SEA-AD/'\n",
    "mapping_result_paths = Path(root_folder).glob('MERSCOPE/resegmentation_and_corr_mapping_data/mtg_manuscript/*/cbg_cpum_mapped.csv')\n",
    "original_taxonomy_path = Path(root_folder).joinpath('RNAseq/scANVI/output/MTG_AD/final.2022-04-14.h5ad')\n",
    "mapping_taxonomy_path = Path(root_folder).joinpath('MERSCOPE/resegmentation_and_corr_mapping_data/mtg_taxonomy_spatial_gene_subset.h5ad')\n",
    "\n",
    "#load metadata tracker\n",
    "h5ad_tracker = pd.read_csv(root_folder+'MERSCOPE/MTG_data_tracker/MTG_h5ad_tracker_SEAAD_072924.csv')\n",
    "h5ad_tracker = h5ad_tracker[h5ad_tracker['Final QC status']!='f']\n",
    "passing_h5ads = h5ad_tracker['Barcode'].astype(str).dropna().values.tolist()\n",
    "\n",
    "#load pseudotime information\n",
    "pseudotime = np.load(Path(root_folder).joinpath('RNAseq/ingest/input/quant_neuropath/MTG/processed/pseudotime.npy'))\n",
    "pseudotime = pd.DataFrame(pseudotime.T, columns=[\"uwa\", \"donor_pseudotime\"])\n",
    "pseudotime[\"uwa\"] = [str(i).replace(\".0\", \"\") for i in pseudotime[\"uwa\"]]\n",
    "pseudotime[\"donor_pseudotime\"] = 1 - pseudotime[\"donor_pseudotime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd8365-ac7d-446d-9ae7-24dc6f300e8d",
   "metadata": {},
   "source": [
    "## Create h5ad for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b04ad2-dfb2-40b7-b4a3-72d4fbaf8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax = read_h5ad(original_taxonomy_path)\n",
    "\n",
    "for mapped_result in mapping_result_paths:\n",
    "\n",
    "    #collect relevant subfiles and unique IDs\n",
    "    if 'cellpose' in str(mapped_result):\n",
    "        barcode = mapped_result.parent.parent.parent.stem\n",
    "        meta_path = str(mapped_result.parent)+'/cellpose_metadata.csv'\n",
    "        cirro_path = str(mapped_result.parent)+'/mapped_102023.h5ad'\n",
    "    else:\n",
    "        barcode = mapped_result.parent.stem\n",
    "        meta_path = str([x for x in mapped_result.parent.glob('**/cellpose_metadata.csv')][0])\n",
    "        cirro_path = str(Path(meta_path).parent)+'/mapped_102023.h5ad'\n",
    "\n",
    "    #skip failed sections\n",
    "    if barcode not in passing_h5ads:\n",
    "        continue\n",
    "\n",
    "    #skip sections that are already mapped\n",
    "    if Path(cirro_path).exists():\n",
    "       continue\n",
    "\n",
    "    #load mapping results\n",
    "    mapping = pd.read_csv(mapped_result, index_col=0)\n",
    "    mapping = mapping.rename(columns={'score.Corr': 'avg.Cor'}) \n",
    "    # # list of columns you'd like to merge with the mapping results\n",
    "    labels_df = tax.obs[['class', 'supertype_scANVI_leiden', 'subclass']]\n",
    "    combo = mapping.reset_index().merge(labels_df.drop_duplicates(), how=\"left\", on='supertype_scANVI_leiden').set_index('index')\n",
    "    combo.index = combo.index.map(lambda x: str(x)[1:])\n",
    "    combo = combo[~combo.index.duplicated()]\n",
    "    combo.index.name = None\n",
    "        \n",
    "    #load cell by gene table \n",
    "    cbg_cpum = pd.read_csv(str(mapped_result.parent)+'/cbg_cpum.csv', index_col=0)\n",
    "    if 'x' in str(cbg_cpum.index.values.tolist()[0]).lower():\n",
    "        cbg_cpum.index = cbg_cpum.index.map(lambda x: str(x)[1:])\n",
    "    else:\n",
    "        cbg_cpum.index = cbg_cpum.index.astype(str)\n",
    "    cbg_cpum = cbg_cpum.loc[combo.index.values,:]\n",
    "\n",
    "    #load filtered cell by gene table (used for mapping)\n",
    "    cbg_filter = pd.read_csv(str(mapped_result.parent)+'/cbg_filtered.csv', index_col=0)\n",
    "    \n",
    "    #create h5ad with all components combined \n",
    "    combo['filename'] = [barcode]*len(combo)\n",
    "    cirro_h5ad = anndata.AnnData(X = cbg_cpum, \n",
    "                                 obs = combo,\n",
    "                                 uns = {'fname' : barcode,\n",
    "                                        'original_taxonomy_path' : original_taxonomy_path,\n",
    "                                        'mapping_taxonomy_path': mapping_taxonomy_path}\n",
    "                                )\n",
    "    cirro_h5ad.obsm['umap'] = UMAP().fit_transform(cbg_cpum)\n",
    "    cirro_h5ad.layers['raw'] = cbg_filter.set_index(cbg_cpum.index.values)\n",
    "    \n",
    "    #add spatial information\n",
    "    meta = pd.read_csv(meta_path, index_col=0)\n",
    "    meta = meta.loc[combo.index.values.astype(np.int64),:]\n",
    "    spatial = meta[['center_x', 'center_y']].values\n",
    "    cirro_h5ad.obsm['spatial'] = spatial \n",
    "    \n",
    "    #save\n",
    "    print('saving: '+ str(cirro_path))\n",
    "    cirro_h5ad.write(cirro_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a486df-e8f4-492c-8653-f7586b76b53f",
   "metadata": {},
   "source": [
    "## Combine into single h5ad, adding metadata\n",
    "- tracker metadata like age, adnc level, etc\n",
    "- pseudotime\n",
    "- spatial_cirro for organized cirro plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff140e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate individual h5ads into a single file with metadata included\n",
    "h5ad_paths = Path(root_folder).glob('MERSCOPE/resegmentation_and_corr_mapping_data/mtg_manuscript/*/*.h5ad')\n",
    "concat_h5ads = [x for x in h5ad_paths if x.parent.stem in passing_h5ads]\n",
    "\n",
    "#initial combination\n",
    "h5ad_raws = []\n",
    "for file in concat_h5ads:\n",
    "    x = read_h5ad(file)\n",
    "    if 'filename' not in x.obs.columns.tolist():\n",
    "        x.obs = x.obs.rename(columns= {'avg.cor' : 'avg.Cor', \n",
    "                                       'cluster': 'supertype_scANVI_leiden', \n",
    "                                       'subclass_scANVI':'subclass', \n",
    "                                       'filename_x': 'filename'})\n",
    "    h5ad_raws.append(x)\n",
    "combo_anndata = anndata.concat(h5ad_raws, uns_merge='first')\n",
    "assert len(combo_anndata.obs.filename.unique().tolist()) == 69\n",
    "combo_anndata.obs_names_make_unique()\n",
    "\n",
    "# # ###prepare to add data from h5ad tracker by making tracker table names uniform\n",
    "selected_rows = h5ad_tracker[['Donor', 'Specimen', 'Barcode', 'UWA ID','Specimen Type', 'Unique Donor ID','technical replicates', 'Dementia', 'Age (Y)', 'Sex', 'Final QC status']]\n",
    "selected_rows['Barcode'] = selected_rows['Barcode'].apply(lambda x: x if pd.isnull(x) else str(int(x)))\n",
    "selected_rows = selected_rows.rename(columns={'Barcode': 'filename', 'UWA ID': 'uwa', 'Specimen type': 'ADNC level'})\n",
    "selected_rows = selected_rows[selected_rows['uwa'].notna()]\n",
    "\n",
    "# ###join pseudotime data on selected h5ad_tracker information\n",
    "selected_rows_pt = pd.merge(selected_rows, pseudotime, on='uwa')\n",
    "selected_rows_pt['uwa'] = selected_rows_pt['uwa'].astype('int')\n",
    "um = combo_anndata.obs['filename'].unique().tolist()\n",
    "selected_rows_pt = selected_rows_pt[selected_rows_pt.filename.isin(um)]\n",
    "h5ad_with_metadata = pd.merge(combo_anndata.obs.reset_index(), selected_rows_pt, on = 'filename', how='left')\n",
    "combo_anndata.obs = h5ad_with_metadata \n",
    "\n",
    "# #remove mangled components from specimen IDs \n",
    "combo_anndata.obs = combo_anndata.obs.replace({\n",
    "    'H21.33.019.Cx30.MTG.02.007.5.1 (H21.33.019.Cx30.MTG.02.007.5.01.02)': 'H21.33.019.Cx30.MTG.02.007.5.1',\n",
    "    'H21.33.019.Cx30.MTG.02.007.5.0 (H21.33.019.Cx30.MTG.02.007.5.01.01)': 'H21.33.019.Cx30.MTG.02.007.5.0',\n",
    "    'H21.33.031.CX24.MTG.02.007.1.01.02?':'H21.33.031.CX24.MTG.02.007.1.01.02',\n",
    "    'H20.33.036.CX24.MTG.02.007.2.01.01?': 'H20.33.036.CX24.MTG.02.007.2.01.01',\n",
    "    'H20.33.036.CX24.MTG.02.007.2.01.02?': 'H20.33.036.CX24.MTG.02.007.2.01.02',\n",
    "    'H20.33.036.CX24.MTG.02.007.2.01.04?': 'H20.33.036.CX24.MTG.02.007.2.01.04',\n",
    "    'H21.33.040.Cx22.MTG.02.007.3.03.01?': 'H21.33.040.Cx22.MTG.02.007.3.03.01',\n",
    "    'H21.33.040.Cx22.MTG.02.007.3.03.03?': 'H21.33.040.Cx22.MTG.02.007.3.03.03',\n",
    "    'H21.33.040.Cx22.MTG.02.007.3.03.04?': 'H21.33.040.Cx22.MTG.02.007.3.03.04',\n",
    "    'H20.33.015.CX24.MTG.02.007.1.03.01?': 'H20.33.015.CX24.MTG.02.007.1.03.01',\n",
    "    'H20.33.015.CX24.MTG.02.007.1.03.02?': 'H20.33.015.CX24.MTG.02.007.1.03.02',\n",
    "    'H20.33.015.CX24.MTG.02.007.1.03.03?': 'H20.33.015.CX24.MTG.02.007.1.03.03'})\n",
    "\n",
    "display(combo_anndata.obs.head())\n",
    "\n",
    "###create unique pt label within donor id\n",
    "upt = {}\n",
    "unique_pt = 0\n",
    "for i in sorted(combo_anndata.obs.donor_pseudotime.unique()):\n",
    "    for j in combo_anndata.obs[combo_anndata.obs['donor_pseudotime']==i].filename.unique():\n",
    "        if j == 'x':\n",
    "            print(j, unique_pt)\n",
    "        upt[j] = unique_pt\n",
    "        unique_pt+=1\n",
    "combo_anndata.obs['unique_pseudotime'] = [upt[x] for x in combo_anndata.obs['filename']]\n",
    "\n",
    "# ##organize h5ad.obsm['spatial_cirro'] by h5ad.obs['donor_pseudotime'] and save\n",
    "counter = 0\n",
    "ycounter = 0\n",
    "ydist = 20000\n",
    "xdist = 30000\n",
    "grid_width = 10\n",
    "if 'spatial_cirro' not in combo_anndata.obsm.keys():\n",
    "    combo_anndata.obsm['spatial_cirro'] = np.empty(combo_anndata.obsm['spatial'].shape)\n",
    "\n",
    "for ii, gb in combo_anndata.obs.groupby(\"unique_pseudotime\"): #ii = section name, gb = indexed chunk of dataframe\n",
    "    spatial = combo_anndata.obsm['spatial'][combo_anndata.obs.unique_pseudotime==ii,:]\n",
    "    spatial = spatial.astype(float)\n",
    "    cirro_y = -(spatial[:,1] - np.mean(spatial[:,1])) - (ycounter*ydist)\n",
    "    cirro_x = (spatial[:,0] - min(spatial[:,0])) +(counter*xdist)\n",
    "    counter += 1\n",
    "    if counter % grid_width == 0:\n",
    "        ycounter += 1\n",
    "        counter = 0\n",
    "    coordinates_cirro = np.column_stack((cirro_x, cirro_y))\n",
    "    combo_anndata.obsm['spatial_cirro'][np.where(combo_anndata.obs.unique_pseudotime==ii)] = coordinates_cirro\n",
    "\n",
    "# add umap and save\n",
    "combo_anndata.obsm['X_umap'] = UMAP().fit_transform(combo_anndata.X) #takes about 40m\n",
    "combo_anndata.write_h5ad(root_folder+'MERSCOPE/results/mtg_noselectedcells_072924.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684dab5-f3ac-40e1-ba13-e3291c861a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
